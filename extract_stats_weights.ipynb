{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical ,Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout, ConvLSTM2D\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from segmentation_models.losses import CategoricalCELoss\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from random import sample, choice, shuffle\n",
    "import tifffile as tiff\n",
    "from skimage.transform import rotate\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "from Patch import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract every patch in a list\n",
    "monthes = ['202007', '202008', '202009', '202011']\n",
    "start_time = time.time()\n",
    "list_patches = Patch.generate_list_patches('/media/wenger/DATA2/dataset_v1/labels')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "dates_to_keep_s2 = []\n",
    "dates_to_keep_s1 = []\n",
    "list_extracted_patches = []\n",
    "\n",
    "for e in list_patches:\n",
    "    days_gap = e.has_days_gap_s2(monthes, date_format='%Y%m', days_gap=17)\n",
    "    if days_gap[1]:\n",
    "        e.extracted_s2 = e.reconstruct_filename('s2', days_gap[0])\n",
    "        list_extracted_patches.append(e)\n",
    "        dates_to_keep_s2.append(e.extracted_s2)\n",
    "\n",
    "'''for e in list_patches:\n",
    "    days_gap = e.has_days_gap_s2(monthes, date_format='%Y%m', days_gap=17)\n",
    "    if days_gap[1]:\n",
    "        dates_to_keep_s1.append(e.reconstruct_filename('s1', days_gap[0]))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means_s2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "stds_s2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "means_s1 = [0, 0]\n",
    "stds_s1 = [0, 0]\n",
    "patch_list_s2 = dates_to_keep_s2\n",
    "patch_list_s1 = []\n",
    "folder_s2 = '/media/wenger/DATA2/dataset_v1/s2'\n",
    "folder_s1 = '/media/wenger/DATA2/dataset_v1/s1'\n",
    "nb_s2 = 0\n",
    "\n",
    "i = 1\n",
    "_debug_list = patch_list_s2[1:500]\n",
    "for dates in patch_list_s2:\n",
    "    for d in dates:\n",
    "        array = tiff.imread(os.path.join(folder_s2, d)).astype(int)\n",
    "\n",
    "        for b in range(0, array.shape[2]):\n",
    "            mean = np.mean(array[:,:,b])\n",
    "            std = np.std(array[:,:,b])\n",
    "            means_s2[b] += mean\n",
    "            stds_s2[b] += std\n",
    "        nb_s2 += 1\n",
    "        \n",
    "    print(str(i) + '/' + str(len(patch_list_s2)))\n",
    "    i+=1\n",
    "\n",
    "'''for patch in patch_list_s1:\n",
    "    array = tiff.imread(os.path.join(folder_s1, patch)).astype(float)\n",
    "    \n",
    "    for b in range(0, array.shape[2]):\n",
    "        mean = np.mean(array[b])\n",
    "        std = np.std(array[b])\n",
    "        means_s1[b] += mean\n",
    "        stds_s1[b] += std'''\n",
    "\n",
    "means_s2_total = [x / nb_s2 for x in means_s2]\n",
    "stds_s2_total = [y / nb_s2 for y in stds_s2]\n",
    "'''means_s1 = means_s1/len(patch_list_s1)\n",
    "stds_s1 = stds_s1/len(patch_list_s1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Means and standard deviation for each 10 bands for 17 days gap for monthes ['202007', '202008', '202009', '202011']\n",
    "stds_s2_total = [439.62790900199644, 702.2237497462481, 786.5948955924482, 1142.9799955196413, 2129.662793514077,\n",
    "                2498.619403949213, 2620.957668050562, 2816.7809424162315, 2212.9231966132015, 1352.3410809599484]\n",
    "\n",
    "means_s2_total = [252.62887057435196, 323.5247227959752, 508.1530443259149, 457.6545855011113, 506.34562773934624,\n",
    "                628.1464899719209, 691.054464119701, 675.529670439067, 720.6092056255868, 612.9317259184817]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_gr = '/media/wenger/DATA2/dataset_v1/ground_reference'\n",
    "classes = np.array([1, 2, 3, 4, 5, 6])\n",
    "frequency = np.zeros(classes.shape, dtype=np.int64)\n",
    "\n",
    "for patch in list_extracted_patches:\n",
    "    array = tiff.imread(os.path.join(folder_gr, patch.reconstruct_filename())).astype(int)\n",
    "\n",
    "    _tmp = np.zeros((array.shape[0], array.shape[1]), dtype=np.int8)\n",
    "\n",
    "    for b in range(0, len(classes)):\n",
    "        if b != (len(classes) - 1):\n",
    "            _tmp += np.where(array == classes[b], b + 1, 0)\n",
    "        else:\n",
    "            _tmp += np.where(array >= classes[b], b + 1, 0)\n",
    "\n",
    "    (unique, counts) = np.unique(_tmp, return_counts=True)\n",
    "    _frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "    for e in _frequencies:\n",
    "        for c in range(0, len(classes)):\n",
    "            if e[0] == classes[c]:\n",
    "                frequency[c] += e[1]\n",
    "\n",
    "class_weights = np.array([1 / nr for nr in frequency])\n",
    "class_weights = (class_weights / np.sum(class_weights) * 1000)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class weights for 6 classes for 17 days gap for monthes ['202007', '202008', '202009', '202011']\n",
    "class_weights = [365.65572762,\n",
    "                 42.46117546,\n",
    "                 71.36785131,\n",
    "                 350.52613946,\n",
    "                 168.5718001,\n",
    "                 1.41730604]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
